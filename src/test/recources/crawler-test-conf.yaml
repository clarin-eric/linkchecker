# Custom configuration for StormCrawler
# This is used to override the default values from crawler-default.xml and provide additional ones 
# for your custom components.
# Use this file with the parameter -conf when launching your extension of ConfigurableTopology.
# This file does not contain all the key values but only the most frequently used ones. See crawler-default.xml for an extensive list.

config:
  topology.workers: 1
  topology.message.timeout.secs: 3600 # 1hour
  topology.max.spout.pending: 5000
  topology.debug: false

  fetcher.threads.number: 1

  # override the JVM parameters for the workers
  topology.worker.childopts: "-Xmx2g -Djava.net.preferIPv4Stack=true"

  # mandatory when using Flux
  topology.kryo.register:
    - com.digitalpebble.stormcrawler.Metadata

  # lists the metadata to persist to storage
  # these are not transfered to the outlinks
  metadata.persist:
    - urlId
    - originalUrl
    - fetch.checkingDate
    - fetch.statusCode
    - fetch.category
    - fetch.message
    - fetch.contentType
    - fetch.byteLength
    - fetch.duration
    - fetch.startTime
    - fetch.redirectCount
    - http.method.head

  http.robots.agents: ""
  http.agent.name: "CLARIN Linkchecker: https://www.clarin.eu/linkchecker"
  http.agent.version: "2.4"
  http.agent.description: "built with StormCrawler Archetype 2.4"
  http.agent.url: "https://www.clarin.eu/linkchecker"
  http.agent.email: "clarin@wowasa.com"
  http.redirectLimit: 20  
  http.timeout: 10000
  
  # using mock proxy server for all requests
  #http.proxy.host: "localhost"
  #http.proxy.port: 8181

  http.protocol.implementation: "com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol"
  https.protocol.implementation: "com.digitalpebble.stormcrawler.protocol.okhttp.HttpProtocol"

  # Defines delay between crawls in the same queue
  fetcher.server.delay: 1
  
  # Defines host specific exceptions from the general crawl delay
  fetcher.server.delay.individual:
    hdl.handle.net: 0.1
  # Defines the delay between crawls in the same queue if a queue has > 1 thread (fetcher.server.delay is use otherwise)
  fetcher.server.min.delay: 1
  # Defines the behavior of fetcher when the crawl-delay in the robots.txt is smaller than the value configured in fetcher.server.delay. 
  # If false the shorter crawl-delay from the robots.txt is used. If true the longer configured delay is forced.
  fetcher.server.delay.force: false
  
  # we decided to accept any crawl delay but we have to swith it off explicitly
  # since otherwise a default of 30 seconds is set in MetricsFetcherBolt
  fetcher.max.crawl.delay: -1

  # The maximum number of bytes for returned HTTP response bodies.
  # Set -1 to disable the limit.
  # this is 0 so that we don't download any payload when doing GET requests, it will get trimmed.
  http.content.limit: 0

  #your SPRING configuration properties go here
  SPRING:
    spring.datasource.url: ${ENV-DATABASE_URI}
    spring.datasource.username: ${ENV-MYSQL_USER}
    spring.datasource.password: ${ENV-MYSQL_PASSWORD}
    spring.datasource.driver-class-name: org.mariadb.jdbc.Driver
    spring.jpa.show-sql: false
    spring.jpa.hibernate.ddl-auto: none
    spring.database-platform: org.hibernate.dialect.MariaDBDialect

  spout.max.results: 5000
  spout.group.max.results: 100

  #Max time to allow between 2 successive queries to the backend. Value in msecs, default 20000.
  # 1 hour
  spout.max.delay.queries: 3600000

  # Min time (in msecs) to allow between 2 successive queries to SQL
  # 3 minutes
  spout.min.delay.queries: 180000
  
  # linkchecker specific settings
  login.list.url: "https://raw.githubusercontent.com/clarin-eric/login-pages/master/list.txt"
  ok.status.codes: [200, 304]
  redirect.status.codes: [301, 302, 303, 307, 308] 
  undeterminded.status.codes: [405, 429]
  restricted.access.status.codes: [401, 403]
  
  directory.share: /data